{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "You are a data scientist working for a school\n",
    "\n",
    "You are asked to predict the GPA of the current students based on the following provided data: \n",
    "\n",
    " 0   StudentID  int64  \n",
    " 1   Age    int64  \n",
    " 2   Gender int64  \n",
    " 3   Ethnicity  int64  \n",
    " 4   ParentalEducation  int64  \n",
    " 5   StudyTimeWeekly    float64\n",
    " 6   Absences   int64  \n",
    " 7   Tutoring   int64  \n",
    " 8   ParentalSupport    int64  \n",
    " 9   Extracurricular    int64  \n",
    " 10  Sports int64  \n",
    " 11  Music  int64  \n",
    " 12  Volunteering   int64  \n",
    " 13  GPA    float64\n",
    " 14  GradeClass float64\n",
    "\n",
    "The GPA is the Grade Point Average, typically ranges from 0.0 to 4.0 in most educational systems, with 4.0 representing an 'A' or excellent performance.\n",
    "\n",
    "The minimum passing GPA can vary by institution, but it's often around 2.0. This usually corresponds to a 'C' grade, which is considered satisfactory.\n",
    "\n",
    "You need to create a Deep Learning model capable to predict the GPA of a Student based on a set of provided features.\n",
    "The data provided represents 2,392 students.\n",
    "\n",
    "In this excersice you will be requested to create a total of three models and select the most performant one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Import Libraries\n",
    "\n",
    "First let's import the following libraries, if there is any library that you need and is not in the list bellow feel free to include it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Load Data\n",
    "\n",
    "- You will be provided with a cvs (comma separated value) file.\n",
    "- You will need to add that file into a pandas dataframe, you can use the following code as reference\n",
    "- The file will be available in canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>ParentalEducation</th>\n",
       "      <th>StudyTimeWeekly</th>\n",
       "      <th>Absences</th>\n",
       "      <th>Tutoring</th>\n",
       "      <th>ParentalSupport</th>\n",
       "      <th>Extracurricular</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Music</th>\n",
       "      <th>Volunteering</th>\n",
       "      <th>GPA</th>\n",
       "      <th>GradeClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.833723</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.929196</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.408756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.042915</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.210570</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112602</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.028829</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.054218</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.672495</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.288061</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>3388</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.680555</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.455509</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>3389</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.583217</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.279150</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>3390</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.805500</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.142333</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>3391</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.416653</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.803297</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>3392</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17.819907</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.140014</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2392 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      StudentID  Age  Gender  Ethnicity  ParentalEducation  StudyTimeWeekly  \\\n",
       "0          1001   17       1          0                  2        19.833723   \n",
       "1          1002   18       0          0                  1        15.408756   \n",
       "2          1003   15       0          2                  3         4.210570   \n",
       "3          1004   17       1          0                  3        10.028829   \n",
       "4          1005   17       1          0                  2         4.672495   \n",
       "...         ...  ...     ...        ...                ...              ...   \n",
       "2387       3388   18       1          0                  3        10.680555   \n",
       "2388       3389   17       0          0                  1         7.583217   \n",
       "2389       3390   16       1          0                  2         6.805500   \n",
       "2390       3391   16       1          1                  0        12.416653   \n",
       "2391       3392   16       1          0                  2        17.819907   \n",
       "\n",
       "      Absences  Tutoring  ParentalSupport  Extracurricular  Sports  Music  \\\n",
       "0            7         1                2                0       0      1   \n",
       "1            0         0                1                0       0      0   \n",
       "2           26         0                2                0       0      0   \n",
       "3           14         0                3                1       0      0   \n",
       "4           17         1                3                0       0      0   \n",
       "...        ...       ...              ...              ...     ...    ...   \n",
       "2387         2         0                4                1       0      0   \n",
       "2388         4         1                4                0       1      0   \n",
       "2389        20         0                2                0       0      0   \n",
       "2390        17         0                2                0       1      1   \n",
       "2391        13         0                2                0       0      0   \n",
       "\n",
       "      Volunteering       GPA  GradeClass  \n",
       "0                0  2.929196         2.0  \n",
       "1                0  3.042915         1.0  \n",
       "2                0  0.112602         4.0  \n",
       "3                0  2.054218         3.0  \n",
       "4                0  1.288061         4.0  \n",
       "...            ...       ...         ...  \n",
       "2387             0  3.455509         0.0  \n",
       "2388             0  3.279150         4.0  \n",
       "2389             1  1.142333         2.0  \n",
       "2390             0  1.803297         1.0  \n",
       "2391             1  2.140014         1.0  \n",
       "\n",
       "[2392 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/PC/OneDrive - Instituto Tecnologico y de Estudios Superiores de Monterrey/Documents/DeepLearning/Student_performance_data _.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Review you data:\n",
    "\n",
    "Make sure you review your data.\n",
    "Place special attention of null or empty values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2392 entries, 0 to 2391\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   StudentID          2392 non-null   int64  \n",
      " 1   Age                2392 non-null   int64  \n",
      " 2   Gender             2392 non-null   int64  \n",
      " 3   Ethnicity          2392 non-null   int64  \n",
      " 4   ParentalEducation  2392 non-null   int64  \n",
      " 5   StudyTimeWeekly    2392 non-null   float64\n",
      " 6   Absences           2392 non-null   int64  \n",
      " 7   Tutoring           2392 non-null   int64  \n",
      " 8   ParentalSupport    2392 non-null   int64  \n",
      " 9   Extracurricular    2392 non-null   int64  \n",
      " 10  Sports             2392 non-null   int64  \n",
      " 11  Music              2392 non-null   int64  \n",
      " 12  Volunteering       2392 non-null   int64  \n",
      " 13  GPA                2392 non-null   float64\n",
      " 14  GradeClass         2392 non-null   float64\n",
      "dtypes: float64(3), int64(12)\n",
      "memory usage: 280.4 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Remove the columns not needed for Student performance prediction\n",
    "\n",
    "- Choose only the columns you consider to be valuable for your model training.\n",
    "- For example, StudentID might not be a good feature for your model, and thus should be removed from your main dataset, which other columns should also be removed?\n",
    "- You can name that final dataset as 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>ParentalEducation</th>\n",
       "      <th>StudyTimeWeekly</th>\n",
       "      <th>Absences</th>\n",
       "      <th>Tutoring</th>\n",
       "      <th>ParentalSupport</th>\n",
       "      <th>Extracurricular</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Music</th>\n",
       "      <th>Volunteering</th>\n",
       "      <th>GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>19.833723</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.929196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>15.408756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.042915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>4.210570</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>10.028829</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.054218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>4.672495</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.288061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  ParentalEducation  StudyTimeWeekly  Absences  Tutoring  \\\n",
       "0   17                  2        19.833723         7         1   \n",
       "1   18                  1        15.408756         0         0   \n",
       "2   15                  3         4.210570        26         0   \n",
       "3   17                  3        10.028829        14         0   \n",
       "4   17                  2         4.672495        17         1   \n",
       "\n",
       "   ParentalSupport  Extracurricular  Sports  Music  Volunteering       GPA  \n",
       "0                2                0       0      1             0  2.929196  \n",
       "1                1                0       0      0             0  3.042915  \n",
       "2                2                0       0      0             0  0.112602  \n",
       "3                3                1       0      0             0  2.054218  \n",
       "4                3                0       0      0             0  1.288061  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here \n",
    "#Eliminar columnas no relevantes para la predicción de GPA\n",
    "dataset = data.drop(['StudentID', 'Gender', 'Ethnicity', 'GradeClass'], axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Check if the columns has any null values:\n",
    "- Here you now have your final dataset to use in your model training.\n",
    "- Before moving foward review your data check for any null or empty value that might be needed to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de valores nulos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age                  0\n",
       "ParentalEducation    0\n",
       "StudyTimeWeekly      0\n",
       "Absences             0\n",
       "Tutoring             0\n",
       "ParentalSupport      0\n",
       "Extracurricular      0\n",
       "Sports               0\n",
       "Music                0\n",
       "Volunteering         0\n",
       "GPA                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "# Verificar valores nulos\n",
    "print(\"Conteo de valores nulos\")\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Prepare your data for training and for testing set:\n",
    " - First create a dataset named X, with all columns but GPA. These are the features\n",
    " - Next create another dataset named y, with only GPA column. This is the label\n",
    " - If you go to your Imports, you will see the following import: **'from sklearn.model_selection import train_test_split'**\n",
    " - Use that *train_test_split* function to create: X_train, X_test, y_train and y_test respectively. Use X and y datasets as parameters. Other parameters to use are: Test Size = 0.2, Random State = 42.\n",
    " \n",
    " - Standarize your features (X_train and X_test) by using the StandardScaler (investigate how to use fit_transform and transform functions). This will help the training process by dealing with normilized data.\n",
    "\n",
    " Note: Your X_train shape should be around (1913, 10). This means the dataset has 10 columns which should be the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1913, 10)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Crear el dataset X y y\n",
    "X = dataset.drop(['GPA'], axis=1)\n",
    "y = data['GPA']\n",
    "\n",
    "# Separar los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Estandarizar los features con StandarScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Revisar dimensiones\n",
    "print(\"Shape of X_train:\", X_train.shape) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Define your Deep Neural Network.\n",
    "- This will be a Sequential Neural Network.\n",
    "- With a Dense input layer with 64 units, and input dimention of 10 and Relu as the activation function.\n",
    "- A Dense hidden layer with 32 units, and Relu as the activation function.\n",
    "- And a Dense output layer with 1 unit, do not define an activation function so it defaults to linear, suitable for regression tasks. e.g. Dense(1)\n",
    "\n",
    "This last part of the output layer is super important, since we want to predict the GPA, this means that we want a regression and not a classification. Linear activation function is best for regression and Sigmoid is best for Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Definir sequiential model\n",
    "model = Sequential()\n",
    "\n",
    "# Agregar input layer \n",
    "model.add(Dense(64, input_dim=10, activation='relu'))\n",
    "\n",
    "# Agregar hidden layer \n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Agregar output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Compile your Neural Network\n",
    "- Choose Adam as the optimizer\n",
    "- And MSE as the Loss function\n",
    "- Also add the following metrics: Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,817</span> (11.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,817\u001b[0m (11.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,817</span> (11.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,817\u001b[0m (11.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here\n",
    "# Compilar el modelo \n",
    "model.compile(optimizer='adam', loss= 'mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# Mostrar la arquitectura\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Fit (or train) your model\n",
    "- Use the X_train and y_train datasets for the training\n",
    "- Do 50 data iterations\n",
    "- Choose the batch size = 10\n",
    "- Also select a validation_split of 0.2\n",
    "- Save the result of the fit function in a variable called 'history'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1.4209 - mean_absolute_error: 0.9012 - val_loss: 0.1220 - val_mean_absolute_error: 0.2812\n",
      "Epoch 2/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1117 - mean_absolute_error: 0.2624 - val_loss: 0.0782 - val_mean_absolute_error: 0.2256\n",
      "Epoch 3/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0687 - mean_absolute_error: 0.2122 - val_loss: 0.0664 - val_mean_absolute_error: 0.2081\n",
      "Epoch 4/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0568 - mean_absolute_error: 0.1919 - val_loss: 0.0658 - val_mean_absolute_error: 0.2110\n",
      "Epoch 5/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0529 - mean_absolute_error: 0.1830 - val_loss: 0.0521 - val_mean_absolute_error: 0.1866\n",
      "Epoch 6/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0477 - mean_absolute_error: 0.1727 - val_loss: 0.0532 - val_mean_absolute_error: 0.1877\n",
      "Epoch 7/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0429 - mean_absolute_error: 0.1662 - val_loss: 0.0520 - val_mean_absolute_error: 0.1830\n",
      "Epoch 8/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0415 - mean_absolute_error: 0.1644 - val_loss: 0.0527 - val_mean_absolute_error: 0.1865\n",
      "Epoch 9/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0395 - mean_absolute_error: 0.1564 - val_loss: 0.0509 - val_mean_absolute_error: 0.1849\n",
      "Epoch 10/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0399 - mean_absolute_error: 0.1598 - val_loss: 0.0516 - val_mean_absolute_error: 0.1841\n",
      "Epoch 11/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0396 - mean_absolute_error: 0.1585 - val_loss: 0.0564 - val_mean_absolute_error: 0.1898\n",
      "Epoch 12/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0363 - mean_absolute_error: 0.1532 - val_loss: 0.0525 - val_mean_absolute_error: 0.1855\n",
      "Epoch 13/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0370 - mean_absolute_error: 0.1529 - val_loss: 0.0543 - val_mean_absolute_error: 0.1854\n",
      "Epoch 14/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0346 - mean_absolute_error: 0.1501 - val_loss: 0.0517 - val_mean_absolute_error: 0.1830\n",
      "Epoch 15/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0328 - mean_absolute_error: 0.1456 - val_loss: 0.0514 - val_mean_absolute_error: 0.1831\n",
      "Epoch 16/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0317 - mean_absolute_error: 0.1430 - val_loss: 0.0529 - val_mean_absolute_error: 0.1834\n",
      "Epoch 17/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0326 - mean_absolute_error: 0.1433 - val_loss: 0.0547 - val_mean_absolute_error: 0.1880\n",
      "Epoch 18/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0338 - mean_absolute_error: 0.1489 - val_loss: 0.0506 - val_mean_absolute_error: 0.1814\n",
      "Epoch 19/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0339 - mean_absolute_error: 0.1471 - val_loss: 0.0513 - val_mean_absolute_error: 0.1815\n",
      "Epoch 20/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0343 - mean_absolute_error: 0.1491 - val_loss: 0.0499 - val_mean_absolute_error: 0.1796\n",
      "Epoch 21/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0313 - mean_absolute_error: 0.1415 - val_loss: 0.0517 - val_mean_absolute_error: 0.1829\n",
      "Epoch 22/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0309 - mean_absolute_error: 0.1409 - val_loss: 0.0652 - val_mean_absolute_error: 0.2020\n",
      "Epoch 23/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0320 - mean_absolute_error: 0.1435 - val_loss: 0.0553 - val_mean_absolute_error: 0.1871\n",
      "Epoch 24/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0301 - mean_absolute_error: 0.1383 - val_loss: 0.0526 - val_mean_absolute_error: 0.1828\n",
      "Epoch 25/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0316 - mean_absolute_error: 0.1409 - val_loss: 0.0575 - val_mean_absolute_error: 0.1912\n",
      "Epoch 26/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0299 - mean_absolute_error: 0.1384 - val_loss: 0.0550 - val_mean_absolute_error: 0.1867\n",
      "Epoch 27/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0297 - mean_absolute_error: 0.1381 - val_loss: 0.0589 - val_mean_absolute_error: 0.1916\n",
      "Epoch 28/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0299 - mean_absolute_error: 0.1365 - val_loss: 0.0519 - val_mean_absolute_error: 0.1839\n",
      "Epoch 29/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0293 - mean_absolute_error: 0.1368 - val_loss: 0.0549 - val_mean_absolute_error: 0.1906\n",
      "Epoch 30/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0295 - mean_absolute_error: 0.1380 - val_loss: 0.0513 - val_mean_absolute_error: 0.1826\n",
      "Epoch 31/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0275 - mean_absolute_error: 0.1324 - val_loss: 0.0505 - val_mean_absolute_error: 0.1820\n",
      "Epoch 32/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0275 - mean_absolute_error: 0.1309 - val_loss: 0.0561 - val_mean_absolute_error: 0.1905\n",
      "Epoch 33/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0273 - mean_absolute_error: 0.1327 - val_loss: 0.0525 - val_mean_absolute_error: 0.1841\n",
      "Epoch 34/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0280 - mean_absolute_error: 0.1327 - val_loss: 0.0540 - val_mean_absolute_error: 0.1858\n",
      "Epoch 35/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0259 - mean_absolute_error: 0.1296 - val_loss: 0.0527 - val_mean_absolute_error: 0.1850\n",
      "Epoch 36/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0277 - mean_absolute_error: 0.1334 - val_loss: 0.0523 - val_mean_absolute_error: 0.1828\n",
      "Epoch 37/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0271 - mean_absolute_error: 0.1302 - val_loss: 0.0569 - val_mean_absolute_error: 0.1904\n",
      "Epoch 38/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0268 - mean_absolute_error: 0.1297 - val_loss: 0.0555 - val_mean_absolute_error: 0.1871\n",
      "Epoch 39/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0266 - mean_absolute_error: 0.1304 - val_loss: 0.0638 - val_mean_absolute_error: 0.2020\n",
      "Epoch 40/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0289 - mean_absolute_error: 0.1350 - val_loss: 0.0531 - val_mean_absolute_error: 0.1819\n",
      "Epoch 41/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0269 - mean_absolute_error: 0.1317 - val_loss: 0.0545 - val_mean_absolute_error: 0.1845\n",
      "Epoch 42/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0249 - mean_absolute_error: 0.1244 - val_loss: 0.0562 - val_mean_absolute_error: 0.1876\n",
      "Epoch 43/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0240 - mean_absolute_error: 0.1208 - val_loss: 0.0610 - val_mean_absolute_error: 0.1970\n",
      "Epoch 44/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0255 - mean_absolute_error: 0.1266 - val_loss: 0.0587 - val_mean_absolute_error: 0.1915\n",
      "Epoch 45/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0237 - mean_absolute_error: 0.1221 - val_loss: 0.0546 - val_mean_absolute_error: 0.1851\n",
      "Epoch 46/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0251 - mean_absolute_error: 0.1248 - val_loss: 0.0558 - val_mean_absolute_error: 0.1863\n",
      "Epoch 47/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0220 - mean_absolute_error: 0.1175 - val_loss: 0.0548 - val_mean_absolute_error: 0.1848\n",
      "Epoch 48/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0234 - mean_absolute_error: 0.1223 - val_loss: 0.0570 - val_mean_absolute_error: 0.1879\n",
      "Epoch 49/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0240 - mean_absolute_error: 0.1231 - val_loss: 0.0567 - val_mean_absolute_error: 0.1891\n",
      "Epoch 50/50\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0225 - mean_absolute_error: 0.1186 - val_loss: 0.0547 - val_mean_absolute_error: 0.1860\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Entrenar el modelo \n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=50,            # Number of iterations\n",
    "    batch_size=10,        # Size of each batch\n",
    "    validation_split=0.2, # Use 20% of the training data for validation\n",
    "    verbose=1             # Display progress during training\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. View your history variable:\n",
    "- Use Matplotlib.pyplot to show graphs of your model traning history\n",
    "- In one graph:\n",
    "   - Plot the Training Loss and the Validation Loss\n",
    "   - X Label = Epochs\n",
    "   - Y Label = Loss\n",
    "   - Title = Training and Validation Loss over Epochs\n",
    "- In a second graph:\n",
    "   - Plot the Training MAE and the Validation MAE\n",
    "   - X Label = Epochs\n",
    "   - Y Label = Mean Absolute Error (MAE)\n",
    "   - Title = Training and Validation MAE over Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here\n",
    "# Extrael los valored de history\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "mae = history.history['mean_absolute_error']\n",
    "val_mae = history.history['val_mean_absolute_error']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# Plot Entrenamiento and Validacion Loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# MAE plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, mae, 'b', label='Training MAE')\n",
    "plt.plot(epochs, val_mae, 'r', label='Validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Absolute Error (MAE)')\n",
    "plt.title('Training and Validation MAE over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar los plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Evaluate your model:\n",
    "- See the result of your loss function.\n",
    "- What can you deduct from there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0612 - mean_absolute_error: 0.1931 \n",
      "Test Loss (MSE): 0.05756184831261635\n",
      "Test Mean Absolute Error (MAE): 0.1890198290348053\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Resultado de la función de perdida\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(f\"Test Loss (MSE): {test_loss}\")\n",
    "print(f\"Test Mean Absolute Error (MAE): {test_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Test Loss (MSE): 0.0576**: El error cuadrático medio (Mean Squared Error, MSE) es una medida de qué tan lejos están las predicciones de los valores reales. Un valor de 0.0576 indica que, en promedio, las predicciones del modelo tienen un error relativamente bajo. Sin embargo, la interpretación depende de la escala del problema; en este caso, el rango típico de GPA va de 0.0 a 4.0, lo que significa que el error es pequeño.\n",
    "\n",
    "- **Test Mean Absolute Error (MAE): 0.1890**: El error absoluto medio (Mean Absolute Error, MAE) representa el promedio de las diferencias absolutas entre las predicciones y los valores reales, expresado en las mismas unidades que el GPA. En este caso, un MAE de 0.1890 significa que, en promedio, las predicciones del modelo se desvían de los valores reales del GPA por aproximadamente 0.19 puntos.\n",
    "\n",
    "### ¿Qué se puede inferir?\n",
    "1. **Precisión del modelo**: El MAE de 0.1890 indica que el modelo tiene una buena precisión, ya que la desviación promedio de las predicciones es menor a 0.2 puntos en una escala de 0 a 4. Esto sugiere que el modelo es capaz de predecir el GPA de los estudiantes con un margen de error aceptable.\n",
    "\n",
    "2. **Generalización**: Dado que los valores de \"loss\" (MSE) y \"mean_absolute_error\" son bajos, se puede inferir que el modelo generaliza bien en el conjunto de datos de prueba. No hay indicios claros de sobreajuste (overfitting) o subajuste (underfitting) según estos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Use your model to make some predictions:\n",
    "- Make predictions of your X_test dataset\n",
    "- Print the each of the predictions and the actual value (which is in y_test)\n",
    "- How good was your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Predicted GPA: 1.54, Actual GPA: 1.43\n",
      "Predicted GPA: 3.27, Actual GPA: 3.12\n",
      "Predicted GPA: 1.74, Actual GPA: 2.04\n",
      "Predicted GPA: 3.43, Actual GPA: 3.55\n",
      "Predicted GPA: 0.53, Actual GPA: 0.25\n",
      "Predicted GPA: 2.52, Actual GPA: 2.63\n",
      "Predicted GPA: 1.44, Actual GPA: 2.06\n",
      "Predicted GPA: 2.46, Actual GPA: 2.25\n",
      "Predicted GPA: 2.06, Actual GPA: 2.19\n",
      "Predicted GPA: 1.06, Actual GPA: 0.76\n",
      "\n",
      "Overall Mean Absolute Error (MAE) on Test Set: 0.19\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Realizar predicciones\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Observar las predicciones y actual values\n",
    "for i in range(10):  # Display the first 10 predictions for comparison\n",
    "    print(f\"Predicted GPA: {y_pred[i][0]:.2f}, Actual GPA: {y_test.iloc[i]:.2f}\")\n",
    "\n",
    "# Evaluar performance by comparando las predicciones y los actual values\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Calcular MAE entre las predicciones y los actual values\n",
    "overall_mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"\\nOverall Mean Absolute Error (MAE) on Test Set: {overall_mae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Compete against this model:\n",
    "- Create two more different models to compete with this model\n",
    "- Here are a few ideas of things you can change:\n",
    "   - During Dataset data engineering:\n",
    "      - You can remove features that you think do not help in the training and prediction \n",
    "      - Feature Scaling: Ensure all features are on a similar scale (as you already did with StandardScaler)\n",
    "   - During Model Definition:\n",
    "      - You can change the Model Architecture (change the type or number of layers or the number of units)\n",
    "      - You can add dropout layers to prevent overfitting\n",
    "   - During Model Compile:\n",
    "      - You can try other optimizer when compiling your model, here some optimizer samples: Adam, RMSprop, or Adagrad.\n",
    "      - Try another Loss Function\n",
    "   - During Model Training:\n",
    "      - Encrease the number of Epochs\n",
    "      - Adjust the size of your batch\n",
    "- Explain in a Markdown cell which changes are you implementing\n",
    "- Show the comparison of your model versus the original model\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2:\n",
    "- Changes:\n",
    "   - **Dataset Data Engineering:** No se realizaron cambios en el conjunto de datos. Las características utilizadas en el Modelo 2 son las mismas que en el modelo original.\n",
    "\n",
    "\n",
    "   - **Model Definition:**\n",
    "   Se redujo el número de unidades en la capa de entrada de 128 (en la versión anterior del Modelo 2) a 64, y en la capa oculta de 64 a 32. Esto disminuye la complejidad del modelo, permitiendo un mejor ajuste a los datos. Se añadió una capa de Dropout con una tasa de 0.2 después de cada capa densa para evitar el sobreajuste. La tasa de dropout fue disminuida en comparación con una prueba anterior que tenía un dropout de 0.3. Y se mantuvieron dos capas densas, pero con una menor cantidad de neuronas en cada capa\n",
    "\n",
    "\n",
    "   - **Model Compile:**\n",
    "   Se cambió el optimizador a Adam, el mismo que fue utilizado en el modelo original, debido a que mostró un mejor desempeño que RMSprop en la prueba anterior del Modelo 2.\n",
    "\n",
    "   - **Model Training:** Se incrementó el número de épocas de entrenamiento a 150 (comparado con 50 en el modelo original)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justificación de los cambios realizados\n",
    "\n",
    "- **Reducción de Unidades:** Se disminuyó el número de unidades en las capas para reducir la complejidad del modelo y mejorar la generalización, evitando el sobreajuste.\n",
    "- **Dropout:** Se añadieron capas de dropout con una tasa de 0.2 para prevenir el sobreajuste, haciendo que el modelo aprenda patrones más robustos.\n",
    "- **Optimizador Adam:** Se mantuvo Adam por su buen desempeño y capacidad de adaptación durante el entrenamiento.\n",
    "- **Incremento de Épocas:** Se aumentaron a 150 para mejorar la precisión, permitiendo al modelo aprender patrones más complejos, controlando el sobreajuste con dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.6946 - mean_absolute_error: 1.0123 - val_loss: 0.1564 - val_mean_absolute_error: 0.3228\n",
      "Epoch 2/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3661 - mean_absolute_error: 0.4714 - val_loss: 0.1080 - val_mean_absolute_error: 0.2695\n",
      "Epoch 3/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2747 - mean_absolute_error: 0.4123 - val_loss: 0.0992 - val_mean_absolute_error: 0.2600\n",
      "Epoch 4/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2223 - mean_absolute_error: 0.3724 - val_loss: 0.0785 - val_mean_absolute_error: 0.2308\n",
      "Epoch 5/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1925 - mean_absolute_error: 0.3458 - val_loss: 0.0641 - val_mean_absolute_error: 0.2076\n",
      "Epoch 6/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2020 - mean_absolute_error: 0.3533 - val_loss: 0.0604 - val_mean_absolute_error: 0.2049\n",
      "Epoch 7/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1788 - mean_absolute_error: 0.3263 - val_loss: 0.0576 - val_mean_absolute_error: 0.1993\n",
      "Epoch 8/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1741 - mean_absolute_error: 0.3231 - val_loss: 0.0576 - val_mean_absolute_error: 0.1981\n",
      "Epoch 9/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1701 - mean_absolute_error: 0.3169 - val_loss: 0.0656 - val_mean_absolute_error: 0.2127\n",
      "Epoch 10/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1575 - mean_absolute_error: 0.3095 - val_loss: 0.0644 - val_mean_absolute_error: 0.2095\n",
      "Epoch 11/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1365 - mean_absolute_error: 0.2852 - val_loss: 0.0638 - val_mean_absolute_error: 0.2081\n",
      "Epoch 12/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1281 - mean_absolute_error: 0.2826 - val_loss: 0.0458 - val_mean_absolute_error: 0.1775\n",
      "Epoch 13/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1287 - mean_absolute_error: 0.2739 - val_loss: 0.0484 - val_mean_absolute_error: 0.1819\n",
      "Epoch 14/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1111 - mean_absolute_error: 0.2579 - val_loss: 0.0476 - val_mean_absolute_error: 0.1796\n",
      "Epoch 15/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1223 - mean_absolute_error: 0.2683 - val_loss: 0.0491 - val_mean_absolute_error: 0.1819\n",
      "Epoch 16/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1083 - mean_absolute_error: 0.2539 - val_loss: 0.0448 - val_mean_absolute_error: 0.1725\n",
      "Epoch 17/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1160 - mean_absolute_error: 0.2667 - val_loss: 0.0554 - val_mean_absolute_error: 0.1915\n",
      "Epoch 18/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1104 - mean_absolute_error: 0.2598 - val_loss: 0.0413 - val_mean_absolute_error: 0.1653\n",
      "Epoch 19/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0957 - mean_absolute_error: 0.2406 - val_loss: 0.0505 - val_mean_absolute_error: 0.1791\n",
      "Epoch 20/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1070 - mean_absolute_error: 0.2512 - val_loss: 0.0577 - val_mean_absolute_error: 0.1949\n",
      "Epoch 21/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1052 - mean_absolute_error: 0.2543 - val_loss: 0.0476 - val_mean_absolute_error: 0.1799\n",
      "Epoch 22/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1097 - mean_absolute_error: 0.2526 - val_loss: 0.0462 - val_mean_absolute_error: 0.1758\n",
      "Epoch 23/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0911 - mean_absolute_error: 0.2352 - val_loss: 0.0438 - val_mean_absolute_error: 0.1702\n",
      "Epoch 24/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1069 - mean_absolute_error: 0.2521 - val_loss: 0.0437 - val_mean_absolute_error: 0.1713\n",
      "Epoch 25/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0923 - mean_absolute_error: 0.2383 - val_loss: 0.0541 - val_mean_absolute_error: 0.1888\n",
      "Epoch 26/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0971 - mean_absolute_error: 0.2415 - val_loss: 0.0420 - val_mean_absolute_error: 0.1678\n",
      "Epoch 27/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0993 - mean_absolute_error: 0.2430 - val_loss: 0.0450 - val_mean_absolute_error: 0.1722\n",
      "Epoch 28/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0898 - mean_absolute_error: 0.2316 - val_loss: 0.0416 - val_mean_absolute_error: 0.1661\n",
      "Epoch 29/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0864 - mean_absolute_error: 0.2255 - val_loss: 0.0431 - val_mean_absolute_error: 0.1684\n",
      "Epoch 30/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0797 - mean_absolute_error: 0.2195 - val_loss: 0.0408 - val_mean_absolute_error: 0.1642\n",
      "Epoch 31/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0930 - mean_absolute_error: 0.2285 - val_loss: 0.0480 - val_mean_absolute_error: 0.1789\n",
      "Epoch 32/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0748 - mean_absolute_error: 0.2140 - val_loss: 0.0501 - val_mean_absolute_error: 0.1804\n",
      "Epoch 33/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0867 - mean_absolute_error: 0.2224 - val_loss: 0.0446 - val_mean_absolute_error: 0.1694\n",
      "Epoch 34/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0796 - mean_absolute_error: 0.2193 - val_loss: 0.0470 - val_mean_absolute_error: 0.1763\n",
      "Epoch 35/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0768 - mean_absolute_error: 0.2141 - val_loss: 0.0484 - val_mean_absolute_error: 0.1777\n",
      "Epoch 36/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0805 - mean_absolute_error: 0.2202 - val_loss: 0.0498 - val_mean_absolute_error: 0.1796\n",
      "Epoch 37/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0874 - mean_absolute_error: 0.2226 - val_loss: 0.0463 - val_mean_absolute_error: 0.1710\n",
      "Epoch 38/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0654 - mean_absolute_error: 0.1994 - val_loss: 0.0479 - val_mean_absolute_error: 0.1780\n",
      "Epoch 39/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0750 - mean_absolute_error: 0.2132 - val_loss: 0.0480 - val_mean_absolute_error: 0.1750\n",
      "Epoch 40/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0695 - mean_absolute_error: 0.2095 - val_loss: 0.0582 - val_mean_absolute_error: 0.1937\n",
      "Epoch 41/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0709 - mean_absolute_error: 0.2080 - val_loss: 0.0461 - val_mean_absolute_error: 0.1737\n",
      "Epoch 42/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0664 - mean_absolute_error: 0.1996 - val_loss: 0.0451 - val_mean_absolute_error: 0.1720\n",
      "Epoch 43/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0737 - mean_absolute_error: 0.2118 - val_loss: 0.0507 - val_mean_absolute_error: 0.1797\n",
      "Epoch 44/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0664 - mean_absolute_error: 0.2032 - val_loss: 0.0525 - val_mean_absolute_error: 0.1838\n",
      "Epoch 45/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0656 - mean_absolute_error: 0.1982 - val_loss: 0.0510 - val_mean_absolute_error: 0.1815\n",
      "Epoch 46/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0662 - mean_absolute_error: 0.1985 - val_loss: 0.0455 - val_mean_absolute_error: 0.1718\n",
      "Epoch 47/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0746 - mean_absolute_error: 0.2169 - val_loss: 0.0446 - val_mean_absolute_error: 0.1703\n",
      "Epoch 48/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0603 - mean_absolute_error: 0.1940 - val_loss: 0.0455 - val_mean_absolute_error: 0.1715\n",
      "Epoch 49/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0733 - mean_absolute_error: 0.2080 - val_loss: 0.0484 - val_mean_absolute_error: 0.1762\n",
      "Epoch 50/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0647 - mean_absolute_error: 0.1975 - val_loss: 0.0412 - val_mean_absolute_error: 0.1643\n",
      "Epoch 51/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0616 - mean_absolute_error: 0.1951 - val_loss: 0.0485 - val_mean_absolute_error: 0.1760\n",
      "Epoch 52/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0639 - mean_absolute_error: 0.1936 - val_loss: 0.0436 - val_mean_absolute_error: 0.1686\n",
      "Epoch 53/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0640 - mean_absolute_error: 0.1961 - val_loss: 0.0627 - val_mean_absolute_error: 0.2020\n",
      "Epoch 54/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0667 - mean_absolute_error: 0.2033 - val_loss: 0.0482 - val_mean_absolute_error: 0.1765\n",
      "Epoch 55/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0591 - mean_absolute_error: 0.1910 - val_loss: 0.0460 - val_mean_absolute_error: 0.1724\n",
      "Epoch 56/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0664 - mean_absolute_error: 0.1999 - val_loss: 0.0514 - val_mean_absolute_error: 0.1818\n",
      "Epoch 57/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0597 - mean_absolute_error: 0.1938 - val_loss: 0.0455 - val_mean_absolute_error: 0.1710\n",
      "Epoch 58/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0629 - mean_absolute_error: 0.1962 - val_loss: 0.0434 - val_mean_absolute_error: 0.1682\n",
      "Epoch 59/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0570 - mean_absolute_error: 0.1836 - val_loss: 0.0453 - val_mean_absolute_error: 0.1722\n",
      "Epoch 60/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0687 - mean_absolute_error: 0.2048 - val_loss: 0.0547 - val_mean_absolute_error: 0.1848\n",
      "Epoch 61/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0603 - mean_absolute_error: 0.1922 - val_loss: 0.0471 - val_mean_absolute_error: 0.1721\n",
      "Epoch 62/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0582 - mean_absolute_error: 0.1887 - val_loss: 0.0441 - val_mean_absolute_error: 0.1693\n",
      "Epoch 63/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0606 - mean_absolute_error: 0.1925 - val_loss: 0.0477 - val_mean_absolute_error: 0.1730\n",
      "Epoch 64/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0620 - mean_absolute_error: 0.1958 - val_loss: 0.0625 - val_mean_absolute_error: 0.2017\n",
      "Epoch 65/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0753 - mean_absolute_error: 0.2070 - val_loss: 0.0479 - val_mean_absolute_error: 0.1729\n",
      "Epoch 66/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0606 - mean_absolute_error: 0.1909 - val_loss: 0.0452 - val_mean_absolute_error: 0.1700\n",
      "Epoch 67/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0643 - mean_absolute_error: 0.1992 - val_loss: 0.0528 - val_mean_absolute_error: 0.1822\n",
      "Epoch 68/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0532 - mean_absolute_error: 0.1808 - val_loss: 0.0463 - val_mean_absolute_error: 0.1716\n",
      "Epoch 69/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0646 - mean_absolute_error: 0.1973 - val_loss: 0.0445 - val_mean_absolute_error: 0.1680\n",
      "Epoch 70/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0601 - mean_absolute_error: 0.1901 - val_loss: 0.0504 - val_mean_absolute_error: 0.1785\n",
      "Epoch 71/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0616 - mean_absolute_error: 0.1953 - val_loss: 0.0454 - val_mean_absolute_error: 0.1704\n",
      "Epoch 72/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0567 - mean_absolute_error: 0.1873 - val_loss: 0.0461 - val_mean_absolute_error: 0.1689\n",
      "Epoch 73/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0553 - mean_absolute_error: 0.1880 - val_loss: 0.0465 - val_mean_absolute_error: 0.1715\n",
      "Epoch 74/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0556 - mean_absolute_error: 0.1865 - val_loss: 0.0516 - val_mean_absolute_error: 0.1786\n",
      "Epoch 75/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0636 - mean_absolute_error: 0.1947 - val_loss: 0.0442 - val_mean_absolute_error: 0.1690\n",
      "Epoch 76/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0535 - mean_absolute_error: 0.1814 - val_loss: 0.0466 - val_mean_absolute_error: 0.1734\n",
      "Epoch 77/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0558 - mean_absolute_error: 0.1822 - val_loss: 0.0557 - val_mean_absolute_error: 0.1867\n",
      "Epoch 78/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0607 - mean_absolute_error: 0.1911 - val_loss: 0.0540 - val_mean_absolute_error: 0.1831\n",
      "Epoch 79/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0558 - mean_absolute_error: 0.1859 - val_loss: 0.0477 - val_mean_absolute_error: 0.1738\n",
      "Epoch 80/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0610 - mean_absolute_error: 0.1948 - val_loss: 0.0451 - val_mean_absolute_error: 0.1698\n",
      "Epoch 81/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0561 - mean_absolute_error: 0.1862 - val_loss: 0.0457 - val_mean_absolute_error: 0.1704\n",
      "Epoch 82/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0600 - mean_absolute_error: 0.1900 - val_loss: 0.0457 - val_mean_absolute_error: 0.1712\n",
      "Epoch 83/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0570 - mean_absolute_error: 0.1881 - val_loss: 0.0484 - val_mean_absolute_error: 0.1760\n",
      "Epoch 84/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0553 - mean_absolute_error: 0.1810 - val_loss: 0.0490 - val_mean_absolute_error: 0.1774\n",
      "Epoch 85/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0548 - mean_absolute_error: 0.1863 - val_loss: 0.0531 - val_mean_absolute_error: 0.1815\n",
      "Epoch 86/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0589 - mean_absolute_error: 0.1889 - val_loss: 0.0449 - val_mean_absolute_error: 0.1702\n",
      "Epoch 87/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0556 - mean_absolute_error: 0.1838 - val_loss: 0.0462 - val_mean_absolute_error: 0.1731\n",
      "Epoch 88/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0567 - mean_absolute_error: 0.1870 - val_loss: 0.0449 - val_mean_absolute_error: 0.1711\n",
      "Epoch 89/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0600 - mean_absolute_error: 0.1915 - val_loss: 0.0473 - val_mean_absolute_error: 0.1734\n",
      "Epoch 90/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0562 - mean_absolute_error: 0.1884 - val_loss: 0.0509 - val_mean_absolute_error: 0.1801\n",
      "Epoch 91/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0584 - mean_absolute_error: 0.1887 - val_loss: 0.0450 - val_mean_absolute_error: 0.1707\n",
      "Epoch 92/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0547 - mean_absolute_error: 0.1826 - val_loss: 0.0517 - val_mean_absolute_error: 0.1796\n",
      "Epoch 93/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0529 - mean_absolute_error: 0.1786 - val_loss: 0.0461 - val_mean_absolute_error: 0.1712\n",
      "Epoch 94/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0531 - mean_absolute_error: 0.1786 - val_loss: 0.0482 - val_mean_absolute_error: 0.1763\n",
      "Epoch 95/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0559 - mean_absolute_error: 0.1851 - val_loss: 0.0457 - val_mean_absolute_error: 0.1709\n",
      "Epoch 96/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0593 - mean_absolute_error: 0.1924 - val_loss: 0.0469 - val_mean_absolute_error: 0.1719\n",
      "Epoch 97/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0538 - mean_absolute_error: 0.1819 - val_loss: 0.0496 - val_mean_absolute_error: 0.1757\n",
      "Epoch 98/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0540 - mean_absolute_error: 0.1828 - val_loss: 0.0471 - val_mean_absolute_error: 0.1720\n",
      "Epoch 99/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0545 - mean_absolute_error: 0.1807 - val_loss: 0.0519 - val_mean_absolute_error: 0.1803\n",
      "Epoch 100/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0537 - mean_absolute_error: 0.1818 - val_loss: 0.0557 - val_mean_absolute_error: 0.1854\n",
      "Epoch 101/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0484 - mean_absolute_error: 0.1714 - val_loss: 0.0453 - val_mean_absolute_error: 0.1708\n",
      "Epoch 102/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0573 - mean_absolute_error: 0.1881 - val_loss: 0.0470 - val_mean_absolute_error: 0.1711\n",
      "Epoch 103/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0534 - mean_absolute_error: 0.1764 - val_loss: 0.0515 - val_mean_absolute_error: 0.1783\n",
      "Epoch 104/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0581 - mean_absolute_error: 0.1885 - val_loss: 0.0482 - val_mean_absolute_error: 0.1733\n",
      "Epoch 105/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0535 - mean_absolute_error: 0.1813 - val_loss: 0.0502 - val_mean_absolute_error: 0.1768\n",
      "Epoch 106/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0602 - mean_absolute_error: 0.1919 - val_loss: 0.0501 - val_mean_absolute_error: 0.1753\n",
      "Epoch 107/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0560 - mean_absolute_error: 0.1820 - val_loss: 0.0469 - val_mean_absolute_error: 0.1703\n",
      "Epoch 108/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0495 - mean_absolute_error: 0.1740 - val_loss: 0.0517 - val_mean_absolute_error: 0.1792\n",
      "Epoch 109/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0514 - mean_absolute_error: 0.1761 - val_loss: 0.0473 - val_mean_absolute_error: 0.1725\n",
      "Epoch 110/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0504 - mean_absolute_error: 0.1748 - val_loss: 0.0588 - val_mean_absolute_error: 0.1892\n",
      "Epoch 111/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0595 - mean_absolute_error: 0.1901 - val_loss: 0.0464 - val_mean_absolute_error: 0.1705\n",
      "Epoch 112/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0497 - mean_absolute_error: 0.1733 - val_loss: 0.0508 - val_mean_absolute_error: 0.1775\n",
      "Epoch 113/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0542 - mean_absolute_error: 0.1832 - val_loss: 0.0519 - val_mean_absolute_error: 0.1774\n",
      "Epoch 114/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0519 - mean_absolute_error: 0.1813 - val_loss: 0.0452 - val_mean_absolute_error: 0.1684\n",
      "Epoch 115/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0526 - mean_absolute_error: 0.1795 - val_loss: 0.0489 - val_mean_absolute_error: 0.1740\n",
      "Epoch 116/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0566 - mean_absolute_error: 0.1890 - val_loss: 0.0486 - val_mean_absolute_error: 0.1729\n",
      "Epoch 117/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0590 - mean_absolute_error: 0.1905 - val_loss: 0.0469 - val_mean_absolute_error: 0.1708\n",
      "Epoch 118/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0530 - mean_absolute_error: 0.1823 - val_loss: 0.0509 - val_mean_absolute_error: 0.1788\n",
      "Epoch 119/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0535 - mean_absolute_error: 0.1815 - val_loss: 0.0481 - val_mean_absolute_error: 0.1730\n",
      "Epoch 120/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0516 - mean_absolute_error: 0.1771 - val_loss: 0.0526 - val_mean_absolute_error: 0.1791\n",
      "Epoch 121/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0503 - mean_absolute_error: 0.1773 - val_loss: 0.0476 - val_mean_absolute_error: 0.1710\n",
      "Epoch 122/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0544 - mean_absolute_error: 0.1832 - val_loss: 0.0457 - val_mean_absolute_error: 0.1678\n",
      "Epoch 123/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0506 - mean_absolute_error: 0.1747 - val_loss: 0.0509 - val_mean_absolute_error: 0.1771\n",
      "Epoch 124/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0542 - mean_absolute_error: 0.1782 - val_loss: 0.0496 - val_mean_absolute_error: 0.1757\n",
      "Epoch 125/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0592 - mean_absolute_error: 0.1863 - val_loss: 0.0466 - val_mean_absolute_error: 0.1704\n",
      "Epoch 126/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0507 - mean_absolute_error: 0.1759 - val_loss: 0.0488 - val_mean_absolute_error: 0.1741\n",
      "Epoch 127/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0519 - mean_absolute_error: 0.1777 - val_loss: 0.0491 - val_mean_absolute_error: 0.1744\n",
      "Epoch 128/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0471 - mean_absolute_error: 0.1710 - val_loss: 0.0501 - val_mean_absolute_error: 0.1762\n",
      "Epoch 129/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0481 - mean_absolute_error: 0.1711 - val_loss: 0.0458 - val_mean_absolute_error: 0.1704\n",
      "Epoch 130/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0486 - mean_absolute_error: 0.1734 - val_loss: 0.0492 - val_mean_absolute_error: 0.1741\n",
      "Epoch 131/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0472 - mean_absolute_error: 0.1722 - val_loss: 0.0457 - val_mean_absolute_error: 0.1711\n",
      "Epoch 132/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0570 - mean_absolute_error: 0.1862 - val_loss: 0.0521 - val_mean_absolute_error: 0.1805\n",
      "Epoch 133/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0524 - mean_absolute_error: 0.1787 - val_loss: 0.0494 - val_mean_absolute_error: 0.1762\n",
      "Epoch 134/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0500 - mean_absolute_error: 0.1744 - val_loss: 0.0502 - val_mean_absolute_error: 0.1774\n",
      "Epoch 135/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0498 - mean_absolute_error: 0.1750 - val_loss: 0.0537 - val_mean_absolute_error: 0.1821\n",
      "Epoch 136/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0485 - mean_absolute_error: 0.1733 - val_loss: 0.0499 - val_mean_absolute_error: 0.1756\n",
      "Epoch 137/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0497 - mean_absolute_error: 0.1726 - val_loss: 0.0478 - val_mean_absolute_error: 0.1739\n",
      "Epoch 138/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0528 - mean_absolute_error: 0.1802 - val_loss: 0.0618 - val_mean_absolute_error: 0.1993\n",
      "Epoch 139/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0520 - mean_absolute_error: 0.1775 - val_loss: 0.0484 - val_mean_absolute_error: 0.1738\n",
      "Epoch 140/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0523 - mean_absolute_error: 0.1802 - val_loss: 0.0528 - val_mean_absolute_error: 0.1821\n",
      "Epoch 141/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0529 - mean_absolute_error: 0.1782 - val_loss: 0.0478 - val_mean_absolute_error: 0.1739\n",
      "Epoch 142/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0505 - mean_absolute_error: 0.1758 - val_loss: 0.0522 - val_mean_absolute_error: 0.1779\n",
      "Epoch 143/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0522 - mean_absolute_error: 0.1781 - val_loss: 0.0471 - val_mean_absolute_error: 0.1728\n",
      "Epoch 144/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0490 - mean_absolute_error: 0.1738 - val_loss: 0.0488 - val_mean_absolute_error: 0.1755\n",
      "Epoch 145/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0556 - mean_absolute_error: 0.1866 - val_loss: 0.0462 - val_mean_absolute_error: 0.1694\n",
      "Epoch 146/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0514 - mean_absolute_error: 0.1786 - val_loss: 0.0492 - val_mean_absolute_error: 0.1759\n",
      "Epoch 147/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0538 - mean_absolute_error: 0.1795 - val_loss: 0.0460 - val_mean_absolute_error: 0.1703\n",
      "Epoch 148/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0503 - mean_absolute_error: 0.1739 - val_loss: 0.0479 - val_mean_absolute_error: 0.1725\n",
      "Epoch 149/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0485 - mean_absolute_error: 0.1743 - val_loss: 0.0475 - val_mean_absolute_error: 0.1710\n",
      "Epoch 150/150\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0521 - mean_absolute_error: 0.1790 - val_loss: 0.0507 - val_mean_absolute_error: 0.1792\n",
      "Modelo 2 Modificado - Test Loss (MSE): 0.0535\n",
      "Modelo 2 Modificado - Test Mean Absolute Error (MAE): 0.1819\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Modelo 2 Modificado\n",
    "model2 = Sequential()\n",
    "\n",
    "# Capa de entrada con menos unidades\n",
    "model2.add(Dense(64, input_dim=10, activation='relu'))\n",
    "model2.add(Dropout(0.2))  # Reducir el dropout a 0.2\n",
    "\n",
    "# Capa oculta con menos unidades\n",
    "model2.add(Dense(32, activation='relu'))\n",
    "model2.add(Dropout(0.2))  # Reducir el dropout a 0.2\n",
    "\n",
    "# Capa de salida\n",
    "model2.add(Dense(1))\n",
    "\n",
    "# Compilar el modelo con el optimizador Adam\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# Entrenar el modelo con menos épocas\n",
    "history2 = model2.fit(X_train, y_train, epochs=150, batch_size=10, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluar el modelo\n",
    "test_loss2, test_mae2 = model2.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"Modelo 2 Modificado - Test Loss (MSE): {test_loss2:.4f}\")\n",
    "print(f\"Modelo 2 Modificado - Test Mean Absolute Error (MAE): {test_mae2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Modelo 2 - Predicciones vs Valores Reales:\n",
      "Predicted GPA: 1.55, Actual GPA: 1.43\n",
      "Predicted GPA: 2.79, Actual GPA: 3.12\n",
      "Predicted GPA: 1.78, Actual GPA: 2.04\n",
      "Predicted GPA: 3.51, Actual GPA: 3.55\n",
      "Predicted GPA: 0.63, Actual GPA: 0.25\n",
      "Predicted GPA: 2.73, Actual GPA: 2.63\n",
      "Predicted GPA: 1.63, Actual GPA: 2.06\n",
      "Predicted GPA: 2.45, Actual GPA: 2.25\n",
      "Predicted GPA: 2.21, Actual GPA: 2.19\n",
      "Predicted GPA: 0.99, Actual GPA: 0.76\n",
      "\n",
      "Overall Mean Absolute Error (MAE) for Modelo 2 on Test Set: 0.18\n"
     ]
    }
   ],
   "source": [
    "# Realizar predicciones para el Modelo 2\n",
    "y_pred2 = model2.predict(X_test)\n",
    "\n",
    "# Observar las primeras 10 predicciones y los valores reales para el Modelo 2\n",
    "print(\"Modelo 2 - Predicciones vs Valores Reales:\")\n",
    "for i in range(10):  # Mostrar las primeras 10 predicciones para comparar\n",
    "    print(f\"Predicted GPA: {y_pred2[i][0]:.2f}, Actual GPA: {y_test.iloc[i]:.2f}\")\n",
    "\n",
    "# Calcular MAE para el Modelo 2\n",
    "overall_mae2 = mean_absolute_error(y_test, y_pred2)\n",
    "print(f\"\\nOverall Mean Absolute Error (MAE) for Modelo 2 on Test Set: {overall_mae2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3:\n",
    "- Changes:\n",
    "   - **Dataset Data Engineering:** Se eliminaron las características menos relevantes: 'Sports', 'Music', 'Volunteering', y 'Extracurricular' para centrarse más en factores directamente relacionados con el rendimiento académico.\n",
    "   - **Model Definition:** Se redujo la arquitectura a una sola capa oculta con 64 unidades.\n",
    "   - **Model Compile:** Se utilizó Adagrad como optimizador en lugar de Adam\n",
    "   - **Model Training:** Se disminuyó el tamaño del lote a 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justificación de los cambios realizados\n",
    "\n",
    "- **Ingeniería de Datos:** Se eliminaron las características 'Sports', 'Music', 'Volunteering', y 'Extracurricular' para centrarse en factores más directamente relacionados con el rendimiento académico.\n",
    "- **Reducción de la Arquitectura:** Se simplificó el modelo a una sola capa oculta con 64 unidades para reducir la complejidad y evitar posibles problemas de sobreajuste.\n",
    "- **Optimizador Adagrad:** Se eligió Adagrad para ajustar automáticamente la tasa de aprendizaje, buscando mejorar la convergencia con características más simplificadas.\n",
    "- **Tamaño del Lote:** Se disminuyó a 5 para hacer actualizaciones más frecuentes del modelo durante el entrenamiento, con el fin de adaptarse mejor a las pequeñas variaciones en los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.9567 - mean_absolute_error: 1.9836 - val_loss: 4.4009 - val_mean_absolute_error: 1.8127\n",
      "Epoch 2/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.5894 - mean_absolute_error: 1.6347 - val_loss: 3.5552 - val_mean_absolute_error: 1.6080\n",
      "Epoch 3/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.7990 - mean_absolute_error: 1.4107 - val_loss: 2.9953 - val_mean_absolute_error: 1.4624\n",
      "Epoch 4/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.4256 - mean_absolute_error: 1.3131 - val_loss: 2.5799 - val_mean_absolute_error: 1.3484\n",
      "Epoch 5/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.1873 - mean_absolute_error: 1.2192 - val_loss: 2.2526 - val_mean_absolute_error: 1.2544\n",
      "Epoch 6/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9678 - mean_absolute_error: 1.1577 - val_loss: 1.9859 - val_mean_absolute_error: 1.1747\n",
      "Epoch 7/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5450 - mean_absolute_error: 1.0183 - val_loss: 1.7638 - val_mean_absolute_error: 1.1046\n",
      "Epoch 8/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4996 - mean_absolute_error: 1.0077 - val_loss: 1.5764 - val_mean_absolute_error: 1.0424\n",
      "Epoch 9/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3429 - mean_absolute_error: 0.9453 - val_loss: 1.4161 - val_mean_absolute_error: 0.9867\n",
      "Epoch 10/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0813 - mean_absolute_error: 0.8518 - val_loss: 1.2775 - val_mean_absolute_error: 0.9359\n",
      "Epoch 11/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0547 - mean_absolute_error: 0.8388 - val_loss: 1.1572 - val_mean_absolute_error: 0.8899\n",
      "Epoch 12/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9319 - mean_absolute_error: 0.7771 - val_loss: 1.0520 - val_mean_absolute_error: 0.8480\n",
      "Epoch 13/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8092 - mean_absolute_error: 0.7379 - val_loss: 0.9597 - val_mean_absolute_error: 0.8104\n",
      "Epoch 14/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7604 - mean_absolute_error: 0.7117 - val_loss: 0.8783 - val_mean_absolute_error: 0.7765\n",
      "Epoch 15/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7359 - mean_absolute_error: 0.7022 - val_loss: 0.8063 - val_mean_absolute_error: 0.7457\n",
      "Epoch 16/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6736 - mean_absolute_error: 0.6737 - val_loss: 0.7425 - val_mean_absolute_error: 0.7173\n",
      "Epoch 17/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6191 - mean_absolute_error: 0.6364 - val_loss: 0.6858 - val_mean_absolute_error: 0.6911\n",
      "Epoch 18/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5471 - mean_absolute_error: 0.5997 - val_loss: 0.6351 - val_mean_absolute_error: 0.6665\n",
      "Epoch 19/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5215 - mean_absolute_error: 0.5819 - val_loss: 0.5897 - val_mean_absolute_error: 0.6432\n",
      "Epoch 20/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4814 - mean_absolute_error: 0.5621 - val_loss: 0.5492 - val_mean_absolute_error: 0.6216\n",
      "Epoch 21/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4483 - mean_absolute_error: 0.5424 - val_loss: 0.5128 - val_mean_absolute_error: 0.6016\n",
      "Epoch 22/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4054 - mean_absolute_error: 0.5159 - val_loss: 0.4800 - val_mean_absolute_error: 0.5828\n",
      "Epoch 23/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3942 - mean_absolute_error: 0.5172 - val_loss: 0.4504 - val_mean_absolute_error: 0.5653\n",
      "Epoch 24/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3595 - mean_absolute_error: 0.4872 - val_loss: 0.4238 - val_mean_absolute_error: 0.5487\n",
      "Epoch 25/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3580 - mean_absolute_error: 0.4881 - val_loss: 0.3997 - val_mean_absolute_error: 0.5332\n",
      "Epoch 26/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3377 - mean_absolute_error: 0.4717 - val_loss: 0.3778 - val_mean_absolute_error: 0.5186\n",
      "Epoch 27/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3061 - mean_absolute_error: 0.4505 - val_loss: 0.3580 - val_mean_absolute_error: 0.5049\n",
      "Epoch 28/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2902 - mean_absolute_error: 0.4367 - val_loss: 0.3400 - val_mean_absolute_error: 0.4922\n",
      "Epoch 29/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2749 - mean_absolute_error: 0.4275 - val_loss: 0.3235 - val_mean_absolute_error: 0.4802\n",
      "Epoch 30/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2729 - mean_absolute_error: 0.4269 - val_loss: 0.3086 - val_mean_absolute_error: 0.4690\n",
      "Epoch 31/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2588 - mean_absolute_error: 0.4215 - val_loss: 0.2949 - val_mean_absolute_error: 0.4583\n",
      "Epoch 32/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2433 - mean_absolute_error: 0.4034 - val_loss: 0.2823 - val_mean_absolute_error: 0.4483\n",
      "Epoch 33/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2292 - mean_absolute_error: 0.3892 - val_loss: 0.2708 - val_mean_absolute_error: 0.4387\n",
      "Epoch 34/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2270 - mean_absolute_error: 0.3914 - val_loss: 0.2603 - val_mean_absolute_error: 0.4298\n",
      "Epoch 35/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2272 - mean_absolute_error: 0.3892 - val_loss: 0.2506 - val_mean_absolute_error: 0.4216\n",
      "Epoch 36/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2214 - mean_absolute_error: 0.3789 - val_loss: 0.2416 - val_mean_absolute_error: 0.4139\n",
      "Epoch 37/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2098 - mean_absolute_error: 0.3756 - val_loss: 0.2334 - val_mean_absolute_error: 0.4065\n",
      "Epoch 38/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1992 - mean_absolute_error: 0.3632 - val_loss: 0.2258 - val_mean_absolute_error: 0.3997\n",
      "Epoch 39/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2000 - mean_absolute_error: 0.3697 - val_loss: 0.2188 - val_mean_absolute_error: 0.3933\n",
      "Epoch 40/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1779 - mean_absolute_error: 0.3398 - val_loss: 0.2122 - val_mean_absolute_error: 0.3872\n",
      "Epoch 41/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1824 - mean_absolute_error: 0.3488 - val_loss: 0.2062 - val_mean_absolute_error: 0.3815\n",
      "Epoch 42/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1767 - mean_absolute_error: 0.3446 - val_loss: 0.2006 - val_mean_absolute_error: 0.3760\n",
      "Epoch 43/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1698 - mean_absolute_error: 0.3345 - val_loss: 0.1955 - val_mean_absolute_error: 0.3707\n",
      "Epoch 44/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1639 - mean_absolute_error: 0.3295 - val_loss: 0.1906 - val_mean_absolute_error: 0.3658\n",
      "Epoch 45/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1717 - mean_absolute_error: 0.3388 - val_loss: 0.1862 - val_mean_absolute_error: 0.3611\n",
      "Epoch 46/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1565 - mean_absolute_error: 0.3184 - val_loss: 0.1820 - val_mean_absolute_error: 0.3568\n",
      "Epoch 47/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1583 - mean_absolute_error: 0.3230 - val_loss: 0.1781 - val_mean_absolute_error: 0.3526\n",
      "Epoch 48/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1553 - mean_absolute_error: 0.3211 - val_loss: 0.1745 - val_mean_absolute_error: 0.3487\n",
      "Epoch 49/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1519 - mean_absolute_error: 0.3202 - val_loss: 0.1711 - val_mean_absolute_error: 0.3449\n",
      "Epoch 50/50\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1509 - mean_absolute_error: 0.3165 - val_loss: 0.1680 - val_mean_absolute_error: 0.3413\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1407 - mean_absolute_error: 0.2868 \n",
      "Modelo 3 - Test Loss (MSE): 0.1408\n",
      "Modelo 3 - Test Mean Absolute Error (MAE): 0.2925\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Elimiarfeatures que quiza sean menos relevantes \n",
    "dataset_simplified = dataset.drop(['Sports', 'Music', 'Volunteering', 'Extracurricular'], axis=1)\n",
    "\n",
    "# Entrenamiento\n",
    "X_simplified = dataset_simplified.drop(['GPA'], axis=1)\n",
    "y_simplified = dataset_simplified['GPA']\n",
    "\n",
    "# Separar dataset simplificado\n",
    "X_train_simplified, X_test_simplified, y_train_simplified, y_test_simplified = train_test_split(X_simplified, y_simplified, test_size=0.2, random_state=42)\n",
    "\n",
    "# Estandarizar \n",
    "scaler_simplified = StandardScaler()\n",
    "X_train_simplified = scaler_simplified.fit_transform(X_train_simplified)\n",
    "X_test_simplified = scaler_simplified.transform(X_test_simplified)\n",
    "\n",
    "# Architecture\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(64, input_dim=X_train_simplified.shape[1], activation='relu'))\n",
    "model3.add(Dense(1))  # Output layer\n",
    "\n",
    "# Compile con Adagrad optimizer\n",
    "model3.compile(optimizer='adagrad', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# Entrenar \n",
    "history3 = model3.fit(X_train_simplified, y_train_simplified, epochs=50, batch_size=5, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluar el modelo 3\n",
    "test_loss3, test_mae3 = model3.evaluate(X_test_simplified, y_test_simplified, verbose=1)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"Modelo 3 - Test Loss (MSE): {test_loss3:.4f}\")\n",
    "print(f\"Modelo 3 - Test Mean Absolute Error (MAE): {test_mae3:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "Modelo 3 - Predicciones vs Valores Reales:\n",
      "Predicted GPA: 1.43, Actual GPA: 1.43\n",
      "Predicted GPA: 2.75, Actual GPA: 3.12\n",
      "Predicted GPA: 1.91, Actual GPA: 2.04\n",
      "Predicted GPA: 3.54, Actual GPA: 3.55\n",
      "Predicted GPA: 0.95, Actual GPA: 0.25\n",
      "Predicted GPA: 2.73, Actual GPA: 2.63\n",
      "Predicted GPA: 1.92, Actual GPA: 2.06\n",
      "Predicted GPA: 1.85, Actual GPA: 2.25\n",
      "Predicted GPA: 2.22, Actual GPA: 2.19\n",
      "Predicted GPA: 0.74, Actual GPA: 0.76\n",
      "\n",
      "Overall Mean Absolute Error (MAE) for Modelo 3 on Test Set: 0.29\n"
     ]
    }
   ],
   "source": [
    "# Realizar predicciones para el Modelo 3\n",
    "y_pred3 = model3.predict(X_test_simplified)\n",
    "\n",
    "# Observar las primeras 10 predicciones y los valores reales para el Modelo 3\n",
    "print(\"\\nModelo 3 - Predicciones vs Valores Reales:\")\n",
    "for i in range(10):  # Mostrar las primeras 10 predicciones para comparar\n",
    "    print(f\"Predicted GPA: {y_pred3[i][0]:.2f}, Actual GPA: {y_test_simplified.iloc[i]:.2f}\")\n",
    "\n",
    "# Calcular MAE para el Modelo 3\n",
    "overall_mae3 = mean_absolute_error(y_test_simplified, y_pred3)\n",
    "print(f\"\\nOverall Mean Absolute Error (MAE) for Modelo 3 on Test Set: {overall_mae3:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tablas comparativas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Test Loss (MSE)</th>\n",
       "      <th>Test MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Modelo 1</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>0.1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Modelo 2</td>\n",
       "      <td>0.0535</td>\n",
       "      <td>0.1819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Modelo 3</td>\n",
       "      <td>0.1408</td>\n",
       "      <td>0.2925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Modelo  Test Loss (MSE)  Test MAE\n",
       "0  Modelo 1           0.0575    0.1890\n",
       "1  Modelo 2           0.0535    0.1819\n",
       "2  Modelo 3           0.1408    0.2925"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear los datos de evaluación para los modelos con valores de ejemplo\n",
    "model_evaluation = {\n",
    "    'Modelo': ['Modelo 1', 'Modelo 2', 'Modelo 3'],\n",
    "    'Test Loss (MSE)': [0.0575, 0.0535, 0.1408],  # Reemplazar con test_loss2 y test_loss3 reales\n",
    "    'Test MAE': [0.1890, 0.1819, 0.2925]  # Reemplazar con test_mae2 y test_mae3 reales\n",
    "}\n",
    "\n",
    "# Crear un DataFrame con los resultados\n",
    "evaluation_df = pd.DataFrame(model_evaluation)\n",
    "evaluation_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student</th>\n",
       "      <th>Modelo 1</th>\n",
       "      <th>Modelo 2</th>\n",
       "      <th>Modelo 3</th>\n",
       "      <th>Actual GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.546593</td>\n",
       "      <td>1.429793</td>\n",
       "      <td>1.427724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.268646</td>\n",
       "      <td>2.787081</td>\n",
       "      <td>2.754623</td>\n",
       "      <td>3.117354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.735960</td>\n",
       "      <td>1.783277</td>\n",
       "      <td>1.911574</td>\n",
       "      <td>2.037769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.427007</td>\n",
       "      <td>3.505158</td>\n",
       "      <td>3.539660</td>\n",
       "      <td>3.548521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.533265</td>\n",
       "      <td>0.632309</td>\n",
       "      <td>0.946850</td>\n",
       "      <td>0.248977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student  Modelo 1  Modelo 2  Modelo 3  Actual GPA\n",
       "0        1  1.535126  1.546593  1.429793    1.427724\n",
       "1        2  3.268646  2.787081  2.754623    3.117354\n",
       "2        3  1.735960  1.783277  1.911574    2.037769\n",
       "3        4  3.427007  3.505158  3.539660    3.548521\n",
       "4        5  0.533265  0.632309  0.946850    0.248977"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un DataFrame con las primeras 5 predicciones para cada modelo y los valores reales\n",
    "\n",
    "# Realizar predicciones para los primeros 5 estudiantes\n",
    "y_pred1 = model.predict(X_test[:5])\n",
    "y_pred2 = model2.predict(X_test[:5])\n",
    "y_pred3 = model3.predict(X_test_simplified[:5])\n",
    "y_actual = y_test.iloc[:5].values\n",
    "\n",
    "# Crear el DataFrame\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Student': [1, 2, 3, 4, 5],\n",
    "    'Modelo 1': y_pred1.flatten(),\n",
    "    'Modelo 2': y_pred2.flatten(),\n",
    "    'Modelo 3': y_pred3.flatten(),\n",
    "    'Actual GPA': y_actual\n",
    "})\n",
    "\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación de los Modelos\n",
    "\n",
    "- **Modelo 1:**\n",
    "  - **Test Loss (MSE):** 0.0575\n",
    "  - **Test MAE:** 0.1890\n",
    "  - El modelo original muestra un error absoluto medio (MAE) de 0.1890, lo que indica que, en promedio, las predicciones se desvían de los valores reales en aproximadamente 0.19 puntos de GPA. Esto sugiere una precisión decente.\n",
    "\n",
    "- **Modelo 2:**\n",
    "  - **Test Loss (MSE):** 0.0535\n",
    "  - **Test MAE:** 0.1819\n",
    "  - Este modelo tiene un menor error en comparación con el modelo original, tanto en términos de MSE como en MAE. Esto indica que los cambios realizados (reducción de unidades en las capas y el uso de dropout) mejoraron ligeramente la capacidad del modelo para predecir el GPA de los estudiantes.\n",
    "\n",
    "- **Modelo 3:**\n",
    "  - **Test Loss (MSE):** 0.1408\n",
    "  - **Test MAE:** 0.2925\n",
    "  - El modelo simplificado tiene el mayor error entre los tres modelos. Su MAE de 0.2925 muestra que las predicciones, en promedio, se desvían casi 0.3 puntos de GPA. Esto sugiere que la simplificación del modelo y la eliminación de ciertas características impactaron negativamente en la precisión.\n",
    "\n",
    "\n",
    "##  Predicciones de los Modelos vs. Valores Reales\n",
    "- **Comparación de las Predicciones:**\n",
    "  - Para la mayoría de los estudiantes, el **Modelo 2** muestra predicciones más cercanas a los valores reales del GPA en comparación con los otros dos modelos.\n",
    "  - El **Modelo 3** parece tener más desviación respecto a los valores reales, especialmente en los estudiantes 2 y 3, lo que concuerda con su mayor MAE.\n",
    "  - El **Modelo 1** también ofrece predicciones aceptables, pero el **Modelo 2** ha demostrado ser ligeramente mejor según el MAE.\n",
    "\n",
    "\n",
    "- **Mejor Modelo:** El **Modelo 2** es el más preciso de los tres, con el menor Test Loss (MSE) y Test MAE. Las modificaciones realizadas, como la inclusión de capas con dropout y el ajuste de unidades, ayudaron a mejorar el desempeño del modelo.\n",
    "- **Peor Modelo:** El **Modelo 3** muestra que la eliminación de ciertas características puede afectar negativamente la precisión, lo que sugiere que las características eliminadas pueden tener un impacto significativo en la predicción del GPA.\n",
    "- **Selección de Características:** La eliminación de ciertas características como en el Modelo 3 demuestra que no todas las simplificaciones son beneficiosas, y algunas características aparentemente no relacionadas pueden influir en el rendimiento académico.\n",
    "\n",
    "La mejor opción es el **Modelo 2**, ya que ofrece la mayor precisión según las métricas de error (MSE y MAE)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
